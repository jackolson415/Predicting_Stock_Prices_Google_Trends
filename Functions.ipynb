{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Collecting Data and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this workbook is to consolidate and generalize the code from API_setup.ipynb and PTON_Modeling.ipynb. Once all of code is consolidated then I will be able to quickly collect and model data for any ticker. \n",
    "\n",
    "Once I have modeled for a few tickers I'll be able to interperet the results of all the selected tickers as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capstone_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import requests\n",
    "import pandas as pd                       \n",
    "from pytrends.request import TrendReq\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "# We are required to do this in order to avoid \"FutureWarning\" issues.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.api import VAR\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see API_setup.ipynb for how I created these functions\n",
    "def spdr_adj_close():\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=spy&apikey=49KFJCFS3P6CEU4F&outputsize=full'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "    df['date'] = df.index\n",
    "    df.index = pd.to_datetime(df['date'])\n",
    "    df = df[df['date'] > '2018-01-01']\n",
    "    df = df[df['date'] < '2021-06-02']\n",
    "    df.drop(columns = 'date', inplace = True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df['5. adjusted close']\n",
    "\n",
    "def create_ticker_df (ticker):\n",
    "    '''Returns a DataFrame of stock and Google Trends data for the given ticker. The output will be daily data 1/2/18-6/1/21'''\n",
    "    #collect stock data using Alpha Vantage API\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={ticker}&apikey=49KFJCFS3P6CEU4F&outputsize=full'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "    \n",
    "    #filter to include 2018.01.02 - 2021.06.01\n",
    "    df['date'] = df.index\n",
    "    df.index = pd.to_datetime(df['date'])\n",
    "    df = df[df['date'] > '2018-01-01']\n",
    "    df = df[df['date'] < '2021-06-02']\n",
    "    df.drop(columns = 'date', inplace = True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    #add lag columns\n",
    "    days_to_lag = [1,2,3,7,30,90,365]\n",
    "    for day in days_to_lag:\n",
    "        df[f'lag_{day}'] = df['5. adjusted close'].shift(day)\n",
    "    \n",
    "    #fix dtypes and column names\n",
    "    df['spdr_adj_close'] = spdr_adj_close()\n",
    "   \n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    df['daily_returns'] = df['5. adjusted close'] - df['lag_1']\n",
    "    df['daily_pct_return'] = df['daily_returns']/df['5. adjusted close'].shift(1)\n",
    "    df['rolling_3d_adj_close'] = df['5. adjusted close'].rolling(3).mean()\n",
    "    df.rename(columns = {'1. open': 'open',\n",
    "                        '2. high': 'high',\n",
    "                        '3. low': 'low',\n",
    "                        '4. close': 'close',\n",
    "                        '5. adjusted close': 'adjusted_close',\n",
    "                        '6. volume': 'volume',\n",
    "                        '7. dividend amount': 'dividend amount',\n",
    "                        '8. split coefficient': 'splitcoef',\n",
    "                        'daily_returns' : 'daily_returns'}, inplace = True)\n",
    "        \n",
    "    #Collect Google Trends data using pytrends api\n",
    "    pytrend = TrendReq()\n",
    "    pytrend.build_payload(kw_list=[ticker])\n",
    "    google = pytrend.interest_over_time()\n",
    "    trends = google[ticker].resample('D', convention = 'start').pad()\n",
    "    trends = pd.DataFrame(trends)\n",
    "    trends.rename(columns = {ticker:'trend_score'}, inplace = True)\n",
    "    \n",
    "    #merge stock data with trends data\n",
    "    df = df.merge(trends, how = 'left', left_index = True, right_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written by Joseph Nelson.\n",
    "\n",
    "def interpret_dftest(dftest):\n",
    "    dfoutput = pd.Series(dftest[0:2], index=['Test Statistic','p-value'])\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predicted_adj_close_df(start_adj_close, preds):\n",
    "    mylist = []\n",
    "    #mylist = [start_adj_close]\n",
    "    for day in preds:\n",
    "        try:\n",
    "            mylist.append(mylist[-1]*(1+day))\n",
    "        except:\n",
    "            mylist.append(start_adj_close)\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cointegration_test(df, alpha=0.05): \n",
    "    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n",
    "    out = coint_johansen(df,-1,5)\n",
    "    d = {'0.90':0, '0.95':1, '0.99':2}\n",
    "    traces = out.lr1\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Summary\n",
    "    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_transformation(df_train, df_forecast, second_diff=False):\n",
    "    \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n",
    "    df_fc = df_forecast.copy()\n",
    "    columns = df_train.columns\n",
    "    for col in columns:        \n",
    "        # Roll back 2nd Diff\n",
    "        if second_diff:\n",
    "            df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1]-df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "        # Roll back 1st Diff\n",
    "        df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
    "    return df_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myticker = 'IBM'\n",
    "df = create_ticker_df(myticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_arima(df):\n",
    "    y_train = df[df.index < datetime(year = 2021, month = 3, day = 1)]\n",
    "    y_test = df[df.index > datetime(year = 2021, month = 3, day = 1)]\n",
    "    y_train = y_train['daily_pct_return']\n",
    "    y_test = y_test['daily_pct_return'] \n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    y_train.dropna(inplace = True)\n",
    "    y_test.dropna(inplace = True)\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b53733610e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split_arima\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-266a38787d4c>\u001b[0m in \u001b[0;36mtrain_test_split_arima\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test_split_arima\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2021\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2021\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'daily_pct_return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'daily_pct_return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "y_train, y_test = train_test_split_arima(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_dftest(adfuller(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_aic(y_train):\n",
    "    # Starting AIC, p, and q.\n",
    "    best_aic = 99 * (10 ** 16)\n",
    "    best_p = 0\n",
    "    best_q = 0\n",
    "\n",
    "    # Use nested for loop to iterate over values of p and q.\n",
    "    for p in range(5):\n",
    "        for q in range(5):\n",
    "        \n",
    "        # Insert try and except statements.\n",
    "            try:\n",
    "            \n",
    "                # Fitting an ARIMA(p, 1, q) model.\n",
    "                #print(f'Attempting to fit ARIMA({p},1,{q})')\n",
    "\n",
    "                # Instantiate ARIMA model.\n",
    "                arima = ARIMA(endog = y_train.astype(float).dropna(), # endog = Y variable\n",
    "                              order = (p,1,q)) # values of p, d, q\n",
    "\n",
    "                # Fit ARIMA model.\n",
    "                model = arima.fit()\n",
    "\n",
    "                # Print out AIC for ARIMA(p, 1, q) model.\n",
    "                #print(f'The AIC for ARIMA({p},1,{q}) is: {model.aic}')\n",
    "\n",
    "                # Is my current model's AIC better than our best_aic?\n",
    "                if model.aic < best_aic:\n",
    "\n",
    "                    # If so, let's overwrite best_aic, best_p, and best_q.\n",
    "                    best_aic = model.aic\n",
    "                    best_p = p\n",
    "                    best_q = q\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    #print()\n",
    "    #print()\n",
    "    print('MODEL FINISHED!')\n",
    "    print(f'Our model that minimizes AIC on the training data is the ARIMA({best_p},1,{best_q}).')\n",
    "    print(f'This model has an AIC of {best_aic}.')\n",
    "    return (best_p,1,best_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_arima_order = find_best_aic(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_arima_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(endog = y_train.astype(float).dropna(), # endog = Y variable\n",
    "              order = best_arima_order)\n",
    "\n",
    "# Fit ARIMA model.\n",
    "arima = model.fit()\n",
    "\n",
    "# Generate predictions based on test set.\n",
    "preds = model.predict(params = arima.params)\n",
    "preds_cuttoff = preds.shape[0]-64\n",
    "preds= preds[preds_cuttoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot training data.\n",
    "plt.plot(y_train.index, pd.DataFrame(y_train), color = 'blue')\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(y_test.index, pd.DataFrame(y_test), color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(y_test.index, preds, color = 'green')\n",
    "\n",
    "plt.title(label = 'PTON Daily % Return with ARIMA(2, 1, 3) Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =df.iloc[-65]['adjusted_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_adj_close = make_predicted_adj_close_df(start, preds)\n",
    "\n",
    "close_train = df[df.index < datetime(year = 2021, month = 3, day = 1)]\n",
    "close_test = df[df.index > datetime(year = 2021, month = 3, day = 1)]\n",
    "close_train = close_train['adjusted_close']\n",
    "close_test = close_test['adjusted_close'] \n",
    "close_train = pd.DataFrame(close_train)\n",
    "close_test = pd.DataFrame(close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot training data.\n",
    "plt.plot(close_train.index, pd.DataFrame(close_train), color = 'blue')\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(close_test.index, pd.DataFrame(close_test), color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(close_test.index, predicted_adj_close, color = 'green')\n",
    "\n",
    "plt.title(label = f'{myticker} Adjusted Close with ARIMA{best_arima_order} Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model with Exogeneous Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_train = df[df.index < datetime(year = 2021, month = 3, day = 1)]\n",
    "gt_train['diff_trend_score']= gt_train['trend_score'].diff(1)\n",
    "\n",
    "gt_train = gt_train['diff_trend_score']\n",
    "\n",
    "endog = y_train.astype(float).dropna()\n",
    "exog = sm.add_constant(gt_train.astype(float).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(endog, exog, order=best_arima_order, trend = 't')\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_with_gt = res.predict()\n",
    "preds_with_gt = preds_with_gt[preds_cuttoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_adj_close = make_predicted_adj_close_df(start, preds_with_gt)\n",
    "predicted_adj_close = predicted_adj_close[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot training data.\n",
    "plt.plot(close_train.index, pd.DataFrame(close_train), color = 'blue')\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(close_test.index, pd.DataFrame(close_test), color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(close_test.index, predicted_adj_close, color = 'green')\n",
    "\n",
    "plt.title(label = f'{myticker} Adjusted Close with SARIMAX Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Autoregression (VAR) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag=12\n",
    "test = 'ssr_chi2test'\n",
    "\n",
    "grangers_causation_matrix(df, variables = ['adjusted_close', 'trend_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trend_score_diff'] = df['trend_score'].diff(1)\n",
    "\n",
    "df = df[['adjusted_close', 'trend_score']]\n",
    "\n",
    "#train_test_split\n",
    "nobs = 30\n",
    "df_train, df_test = df[0:-nobs], df[-nobs:]\n",
    "\n",
    "df_differenced = df_train.diff().dropna()\n",
    "\n",
    "model = VAR(df_differenced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest = 100_000\n",
    "for i in [1,2,3,4,5,6,7,8,9]:\n",
    "    print(i)\n",
    "    result = model.fit(i)\n",
    "    print('Lag Order =', i)\n",
    "    print('AIC : ', result.aic)\n",
    "    if result.aic < lowest:\n",
    "        lowest = result.aic\n",
    "        best_lag = i\n",
    "    #print('BIC : ', result.bic)\n",
    "    #print('FPE : ', result.fpe)\n",
    "    #print('HQIC: ', result.hqic, '\\n')\n",
    "\n",
    "print('\\n')\n",
    "print(f'best lag: {best_lag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = model.fit(best_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_input = df_differenced.values[-best_lag:]\n",
    "\n",
    "fc = var.forecast(y=forecast_input, steps=nobs)\n",
    "df_forecast = pd.DataFrame(fc, index=df_test.index[-nobs:], columns=df_train.columns + '_2d')\n",
    "\n",
    "df_results = invert_transformation(df_train, df_forecast, second_diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_adj_close = df_results['adjusted_close_forecast']\n",
    "\n",
    "close_test = df_test[df_test.index > datetime(year = 2021, month = 3, day = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(close_test.index, pd.DataFrame(close_test)['adjusted_close'], color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(predicted_adj_close.index, predicted_adj_close, color = 'green')\n",
    "\n",
    "plt.title(label = f'{myticker} Adjusted Close and Google Trends Score with VAR Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_train = df[df.index < datetime(year = 2021, month = 4, day = 21)]\n",
    "close_train = close_train['adjusted_close']\n",
    "close_train = pd.DataFrame(close_train)\n",
    "close_test = pd.DataFrame(close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_adj_close = df_results['adjusted_close_forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot training data.\n",
    "plt.plot(close_train.index, pd.DataFrame(close_train), color = 'blue')\n",
    "# Plot training data.\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(close_test.index, pd.DataFrame(close_test)['adjusted_close'], color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(close_test.index, predicted_adj_close, color = 'green')\n",
    "\n",
    "plt.title(label = f'{myticker} Adjusted Close with VAR Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
